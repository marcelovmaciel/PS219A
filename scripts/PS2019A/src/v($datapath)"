read_delim                package:readr                R Documentation

_R_e_a_d _a _d_e_l_i_m_i_t_e_d _f_i_l_e (_i_n_c_l_u_d_i_n_g _C_S_V _a_n_d _T_S_V) _i_n_t_o _a _t_i_b_b_l_e

_D_e_s_c_r_i_p_t_i_o_n:

     ‘read_csv()’ and ‘read_tsv()’ are special cases of the more
     general ‘read_delim()’. They're useful for reading the most common
     types of flat file data, comma separated values and tab separated
     values, respectively. ‘read_csv2()’ uses ; for the field separator
     and , for the decimal point. This format is common in some
     European countries.

_U_s_a_g_e:

     read_delim(
       file,
       delim = NULL,
       quote = "\"",
       escape_backslash = FALSE,
       escape_double = TRUE,
       col_names = TRUE,
       col_types = NULL,
       col_select = NULL,
       id = NULL,
       locale = default_locale(),
       na = c("", "NA"),
       quoted_na = TRUE,
       comment = "",
       trim_ws = FALSE,
       skip = 0,
       n_max = Inf,
       guess_max = min(1000, n_max),
       name_repair = "unique",
       num_threads = readr_threads(),
       progress = show_progress(),
       show_col_types = should_show_types(),
       skip_empty_rows = TRUE,
       lazy = TRUE
     )
     
     read_csv(
       file,
       col_names = TRUE,
       col_types = NULL,
       col_select = NULL,
       id = NULL,
       locale = default_locale(),
       na = c("", "NA"),
       quoted_na = TRUE,
       quote = "\"",
       comment = "",
       trim_ws = TRUE,
       skip = 0,
       n_max = Inf,
       guess_max = min(1000, n_max),
       name_repair = "unique",
       num_threads = readr_threads(),
       progress = show_progress(),
       show_col_types = should_show_types(),
       skip_empty_rows = TRUE,
       lazy = TRUE
     )
     
     read_csv2(
       file,
       col_names = TRUE,
       col_types = NULL,
       col_select = NULL,
       id = NULL,
       locale = default_locale(),
       na = c("", "NA"),
       quoted_na = TRUE,
       quote = "\"",
       comment = "",
       trim_ws = TRUE,
       skip = 0,
       n_max = Inf,
       guess_max = min(1000, n_max),
       progress = show_progress(),
       name_repair = "unique",
       num_threads = readr_threads(),
       show_col_types = should_show_types(),
       skip_empty_rows = TRUE,
       lazy = TRUE
     )
     
     read_tsv(
       file,
       col_names = TRUE,
       col_types = NULL,
       col_select = NULL,
       id = NULL,
       locale = default_locale(),
       na = c("", "NA"),
       quoted_na = TRUE,
       quote = "\"",
       comment = "",
       trim_ws = TRUE,
       skip = 0,
       n_max = Inf,
       guess_max = min(1000, n_max),
       progress = show_progress(),
       name_repair = "unique",
       num_threads = readr_threads(),
       show_col_types = should_show_types(),
       skip_empty_rows = TRUE,
       lazy = TRUE
     )
     
_A_r_g_u_m_e_n_t_s:

    file: Either a path to a file, a connection, or literal data
          (either a single string or a raw vector).

          Files ending in ‘.gz’, ‘.bz2’, ‘.xz’, or ‘.zip’ will be
          automatically uncompressed. Files starting with http://,
          https://, ftp://, or ftps:// will be automatically
          downloaded. Remote gz files can also be automatically
          downloaded and decompressed.

          Literal data is most useful for examples and tests. To be
          recognised as a path, it must be wrapped with ‘I()’, be a
          string containing at least one new line, or be a vector
          containing at least one string with a new line.

          Using a value of ‘clipboard()’ will read from the system
          clipboard.

   delim: Single character used to separate fields within a record.

   quote: Single character used to quote strings.

escape_backslash: Does the file use backslashes to escape special
          characters? This is more general than ‘escape_double’ as
          backslashes can be used to escape the delimiter character,
          the quote character, or to add special characters like \\n.

escape_double: Does the file escape quotes by doubling them? i.e. If
          this option is ‘TRUE’, the value """" represents a single
          quote, \".

col_names: Either ‘TRUE’, ‘FALSE’ or a character vector of column
          names.

          If ‘TRUE’, the first row of the input will be used as the
          column names, and will not be included in the data frame. If
          ‘FALSE’, column names will be generated automatically: X1,
          X2, X3 etc.

          If ‘col_names’ is a character vector, the values will be used
          as the names of the columns, and the first row of the input
          will be read into the first row of the output data frame.

          Missing (‘NA’) column names will generate a warning, and be
          filled in with dummy names ‘X1’, ‘X2’ etc. Duplicate column
          names will generate a warning and be made unique, see
          ‘name_repair’ to control how this is done.

col_types: One of ‘NULL’, a ‘cols()’ specification, or a string. See
          ‘vignette("readr")’ for more details.

          If ‘NULL’, all column types will be imputed from the first
          1000 rows on the input. This is convenient (and fast), but
          not robust. If the imputation fails, you'll need to increase
          the ‘guess_max’ or supply the correct types yourself.

          Column specifications created by ‘list()’ or ‘cols()’ must
          contain one column specification for each column. If you only
          want to read a subset of the columns, use ‘cols_only()’.

          Alternatively, you can use a compact string representation
          where each character represents one column:

            • c = character

            • i = integer

            • n = number

            • d = double

            • l = logical

            • f = factor

            • D = date

            • T = date time

            • t = time

            • ? = guess

            • _ or - = skip

              By default, reading a file without a column specification
              will print a message showing what ‘readr’ guessed they
              were. To remove this message, set ‘show_col_types =
              FALSE’ or set `options(readr.show_col_types = FALSE).

col_select: <‘tidy-select’> Columns to include in the results, either
          by name or by numeric index. Use ‘c()’ or ‘list()’ to select
          with more than one expression and ‘?tidyselect::language’ for
          full details on the selection language.

      id: The name of a column in which to store the file path. This is
          useful when reading multiple input files and there is data in
          the file paths, such as the data collection date. If ‘NULL’
          (the default) no extra column is created.

  locale: The locale controls defaults that vary from place to place.
          The default locale is US-centric (like R), but you can use
          ‘locale()’ to create your own locale that controls things
          like the default time zone, encoding, decimal mark, big mark,
          and day/month names.

      na: Character vector of strings to interpret as missing values.
          Set this option to ‘character()’ to indicate no missing
          values.

quoted_na: Should missing values inside quotes be treated as missing
          values (the default) or strings.

 comment: A string used to identify comments. Any text after the
          comment characters will be silently ignored.

 trim_ws: Should leading and trailing whitespace (ASCII spaces and
          tabs) be trimmed from each field before parsing it?

    skip: Number of lines to skip before reading data. If ‘comment’ is
          supplied any commented lines are ignored _after_ skipping.

   n_max: Maximum number of lines to read.

guess_max: Maximum number of lines to use for guessing column types.

name_repair: Treatment of problematic column names:

            • ‘"minimal"’: No name repair or checks, beyond basic
              existence of names

            • ‘"unique"’: Make sure names are unique and not empty

            • ‘"check_unique"’: (default value), no name repair, but
              check they are ‘unique’

            • ‘"universal"’: Make the names ‘unique’ and syntactic

            • a function: apply custom name repair (e.g., ‘.name_repair
              = make.names’ for names in the style of base R)

            • A purrr-style anonymous function, see
              ‘rlang::as_function()’

          This argument is passed on as ‘repair’ to
          ‘vctrs::vec_as_names()’. See there for more details on these
          terms and the strategies used to enforce them.

num_threads: The number of processing threads to use for initial
          parsing and lazy reading of data. If your data contains
          newlines within fields the parser should automatically detect
          this and fall back to using one thread only. However if you
          know your file has newlines within quoted fields it is safest
          to set ‘num_threads = 1’ explicitly.

progress: Display a progress bar? By default it will only display in an
          interactive session and not while knitting a document. The
          automatic progress bar can be disabled by setting option
          ‘readr.show_progress’ to ‘FALSE’.

show_col_types: If ‘FALSE’, do not show the guessed column types. If
          ‘TRUE’ always show the column types, even if they are
          supplied. If ‘NULL’ (the default) only show the column types
          if they are not explicitly supplied by the ‘col_types’
          argument.

skip_empty_rows: Should blank rows be ignored altogether? i.e. If this
          option is ‘TRUE’ then blank rows will not be represented at
          all.  If it is ‘FALSE’ then they will be represented by ‘NA’
          values in all the columns.

    lazy: Read values lazily? By default the file is initially only
          indexed and the values are read lazily when accessed. Lazy
          reading is useful interactively, particularly if you are only
          interested in a subset of the full dataset. Note, lazy
          reading on windows will lock the file until all the data has
          been read from it, if you run into this issue set ‘lazy =
          FALSE’.

_V_a_l_u_e:

     A ‘tibble()’. If there are parsing problems, a warning will alert
     you. You can retrieve the full details by calling ‘problems()’ on
     your dataset.

_E_x_a_m_p_l_e_s:

     # Input sources -------------------------------------------------------------
     # Read from a path
     read_csv(readr_example("mtcars.csv"))
     read_csv(readr_example("mtcars.csv.zip"))
     read_csv(readr_example("mtcars.csv.bz2"))
     ## Not run:
     
     # Including remote paths
     read_csv("https://github.com/tidyverse/readr/raw/master/inst/extdata/mtcars.csv")
     ## End(Not run)
     
     
     # Or directly from a string with `I()`
     read_csv(I("x,y\n1,2\n3,4"))
     
     # Column types --------------------------------------------------------------
     # By default, readr guesses the columns types, looking at the first 1000 rows.
     # You can override with a compact specification:
     read_csv(I("x,y\n1,2\n3,4"), col_types = "dc")
     
     # Or with a list of column types:
     read_csv(I("x,y\n1,2\n3,4"), col_types = list(col_double(), col_character()))
     
     # If there are parsing problems, you get a warning, and can extract
     # more details with problems()
     y <- read_csv(I("x\n1\n2\nb"), col_types = list(col_double()))
     y
     problems(y)
     
     # File types ----------------------------------------------------------------
     read_csv(I("a,b\n1.0,2.0"))
     read_csv2(I("a;b\n1,0;2,0"))
     read_tsv(I("a\tb\n1.0\t2.0"))
     read_delim(I("a|b\n1.0|2.0"), delim = "|")
     

